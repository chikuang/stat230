% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{mathtools}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Stat 230 Introduction to Probability},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Stat 230 Introduction to Probability}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Winter 2024}
\author{Chi-Kuang Yeh\\
University of Waterloo}
\date{2024-02-16}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{information-of-the-course}{%
\chapter{Information of the course}\label{information-of-the-course}}

The purpose of this page is to hold some of the additional materials provided by myself. Students should consult UW \href{https://api-4ccc589b.duosecurity.com/frame/v4/preauth/healthcheck?sid=frameless-c0657e9d-cb86-4ac9-a6a7-fd054ae21fd5}{Learn} system.

\hypertarget{course-description}{%
\section{Course description}\label{course-description}}

This course provides an introduction to probability models including sample spaces, mutually exclusive and independent events, conditional probability and Bayes' Theorem. The named distributions (Discrete Uniform, Hypergeometric, Binomial, Negative Binomial, Geometric, Poisson, Continuous Uniform, Exponential, Normal (Gaussian), and Multinomial) are used to model real phenomena. Discrete and continuous univariate random variables and their distributions are discussed. Joint probability functions, marginal probability functions, and conditional probability functions of two or more discrete random variables and functions of random variables are also discussed. Students learn how to calculate and interpret means, variances and covariances particularly for the named distributions. The Central Limit Theorem is used to approximate probabilities.

\hypertarget{instructor}{%
\subsection{Instructor}\label{instructor}}

Chi-Kuang Yeh, I am a postdoc at the \emph{Department of Statistics and Actuarial Science}.

\begin{itemize}
\tightlist
\item
  Office: M3--3102 Desk 10, but I hold office hour at M3 - 2101 Desk 1, 9:30 -- 10:30 on Tuesday.
\item
  Email: \href{mailto:chi-kuang.yeh@uwaterloo.ca}{\nolinkurl{chi-kuang.yeh@uwaterloo.ca}}
\end{itemize}

\hypertarget{course-coordinator}{%
\subsection{Course Coordinator}\label{course-coordinator}}

Dr.~\href{https://uwaterloo.ca/scholar/ehintz}{Erik Hintz}.

\begin{itemize}
\tightlist
\item
  Office: M3--2106
\item
  Email: \href{mailto:erik.hintz@uwaterloo.ca}{erik.hintz@uuwaterloo.ca}
\end{itemize}

\hypertarget{logistic-issue}{%
\subsection{Logistic Issue}\label{logistic-issue}}

Contact Divya Lala

\begin{itemize}
\tightlist
\item
  Email: \href{mailto:divya.lala@uwaterloo.ca}{\nolinkurl{divya.lala@uwaterloo.ca}} or the undergrad advising email \href{mailto:sasugradadv@uwaterloo.ca}{\nolinkurl{sasugradadv@uwaterloo.ca}}.
\end{itemize}

\hypertarget{exam-and-tutorial-assessment-date}{%
\subsection{EXAM and Tutorial assessment Date}\label{exam-and-tutorial-assessment-date}}

Midterm

\begin{itemize}
\tightlist
\item[$\boxtimes$]
  Midterm 1: February 08, 2024 16:30--17:50 (Coverage Ch. 1 -- 5.1)
\item[$\square$]
  Midterm 2: March 14, 2024 16:30--17:50
\end{itemize}

Final

\begin{itemize}
\tightlist
\item[$\square$]
  Tuesday April 16, 2024 19:30 -- 22:00. Location: TBA
\end{itemize}

Tutorial assessment

\begin{itemize}
\tightlist
\item[$\boxtimes$]
  Tutorial quiz 1: January 26, 2024 (Coverage Ch. 1--3)
\item[$\boxtimes$]
  Tutorial test 1: February 02, 2024 (Coverage Ch. 1--4)
\item[$\square$]
  Tutorial quiz 2: March 01, 2024
\item[$\square$]
  Tutorial test 2: March 08, 2024
\item[$\square$]
  Tutorial quiz 3: March 22, 2024
\item[$\square$]
  Tutorial test 3: April 05, 2024
\end{itemize}

\hypertarget{chapters-and-associated-lectures}{%
\section{Chapters and associated Lectures}\label{chapters-and-associated-lectures}}

Those chapters are based on the lecture notes. The lecture covered is based on \emph{Section 002}. This part will be updated frequently.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Chapter & Title & Lecture Covered \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Introduction to Probability & 1 \\
2 & Mathematical Probability Models & 2--3 \\
3 & Probability and Counting Techniques & 3--6 \\
4 & Probability rules and Conditional Probability & 6--9 \\
5 & Discrete Random Variable & 10 --16 \\
6 & TBA & TBA \\
7 & Expected Value and Variance & 16 -- \\
8 & TBA & TBA \\
9 & TBA & TBA \\
10 & TBA & TBA \\
\end{longtable}

\hypertarget{lecture-1-january-08-2024}{%
\chapter{Lecture 1, January 08, 2024}\label{lecture-1-january-08-2024}}

In this lecture, we went over

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Course syllabus and rules
\item
  Chapter 1 -- Basic definition of probability. We also saw the potential ambiguities when defining probabilities.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{definition}[Classical Definition of probability]
The \textbf{classical} definition: The probability of some event is
\[
\frac{\mathrm{number~of~ways~the~event~can~occur~}}
{\mathrm{{the~total~number~of~possible~outcomes}}},
\]
provided all outcomes are \emph{equally likely}.
\end{definition}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{definition}[Relative Frequency Definition of of probability]
The \textbf{relative frequency} definition: The probability of an event
is the (limiting) proportion (or fraction) of times the event occurs in a very
long series of repetitions of an experiment.
\end{definition}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{definition}[Subjective Definition of Probability]
The \textbf{subjective} definition: The probability of an event is a measure of how sure the person making the statement is that the event will happen.
\end{definition}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Problem}: Each of the above definitions has pitfall:

\begin{itemize}
\tightlist
\item
  Classical: We may not be able to know the total number of possible outcomes, or it may be uncountable
\item
  Relative frequency: We need ``repetition'', which is often expensive and may not be possible.
\item
  Subjective: We want the probability to be consistent across different people, and and be rigorously defined.
\end{itemize}

\hypertarget{lecture-2-january-10-2024}{%
\chapter{Lecture 2, January 10, 2024}\label{lecture-2-january-10-2024}}

In this lecture, we went over some basic definitions from the set theory, and using them as the building block for the rest of the course. We started Chapter 2 today, with many definitions.

As for the set operations, \(\cup,\cap,A^c,...\), the Venn diagrams help to visual the meaning behind. Here is a good reference \href{https://www.edrawmax.com/article/venn-diagram-symbols-and-set-notations.html}{HERE}.

\begin{definition}[sample space]
A \textbf{sample space} \(S\) is a \emph{set} of distinct outcomes of an experiment with the property that in a single trial of the experiment only one of these outcomes occurs.
\end{definition}

\begin{definition}[Discrete and non-discrete sample space]
A sample space \(S\) is said to be \textbf{discrete} if it is finite, or ``countably infinite'' (i.e.,there is a one-to-one correspondence with the natural numbers). Otherwise a sample space is said to be \textbf{non-discrete}.
\end{definition}

\begin{definition}[Event]
An \textbf{event} is a subset of the sample space that can be assigned probability.
\end{definition}

\begin{definition}[Simple and Compound event]
Let \(S\) be discrete and \(A\subset S\) an event. If \(A\) is indivisible so it contains only one point, we call it a \textbf{simple event}, otherwise \textbf{compound event}.
\end{definition}

\begin{definition}[Probability distribution]
Let \(S=\{a_1,a_2,\dots\}\) be discrete. Assign numbers \(P(\{a_i\})\) (or short: \(P(a_i)\)), \(i=1,2,\dots\), so that

1.\(0\leq P(a_i)\leq 1,\quad i=1,2,\dots\)
2. \(\sum_{\text{all }i}P(a_i)=1\).

We then call the set of probabilities \(\{P(a_i):i=1,2,\dots\}\) a \textbf{probability distribution}.
\end{definition}

\begin{definition}
Let \(S=\{a_1,a_2,\dots\}\) discrete. From any prob. distribution \(P\) on \(S\) we can define a prob. measure on \$ \{\mathcal S\} = 2\^{}S\$ (set of all subsets of \(S\)) by
\[\forall A \subseteq S \qquad P(A)=\sum_{a_i\in A}P(a_i).\]
\end{definition}

\begin{definition}[Equally likely]
We say a sample space \(S\) with a finite number of outcomes is \textbf{equally likely} if the probability of every individual outcome in \(S\) is the same.
\end{definition}

Observe that

\begin{itemize}
\item
  If \(|A|\) denote the number of outcomes in an event \(A\). In case of an equally likely sample space,
  \[
  1=P(S)=\sum_{i=1}^{|S|}P(a_{i})= P(a_i)|S|.
  \]
  \[
  P(a_i)=\frac{1}{|S|}.
  \]
\item
  Hence,
  \[P(A) = \sum_{i:\;a_i \in A} P(a_i) = \sum_{i:\;a_i \in A} \frac{1}{|S|} =|A|\cdot  \frac{1}{|S|}\]
\end{itemize}

\textbf{Conclusion}: In a \textbf{finite, equally likely sample space}, the probability of an event \(A\) can be computed as
\[
P(A) = \sum_{i:\;a_i \in A} P(a_i) = \frac{|A|}{|S|}.
\]

\hypertarget{questions-from-the-class}{%
\section{Questions from the class}\label{questions-from-the-class}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the difference between ``countably infinite'' v.s. ``infinite''?
\end{enumerate}

Ans: A set is \emph{countably infinite} if its elements can be put in one-to-one correspondence with the set of natural numbers \(\mathbb{N}\). Alternatively, you can think that a set is countably infinite if you can count off all elements in the set in such a way that, even though the counting will take forever, you will get to any particular element in a finite amount of time. {[}\href{https://mathinsight.org/definition/countably_infinite}{A good reference page to read}{]}. If a set is not countable or countably infinite, it is infinite.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Why do we have something such as \(2^\mathcal{S}\) in the lecture?
\end{enumerate}

Ans: It is related to something called the \emph{power set}. The power set consists all the possible subset of a set \(\mathcal{S}\). In a subset of \(S\), (i.e.~\(A \subseteq \mathcal{S}\), every element in \(\mathcal{S}\) may be either in \(A\) or not in \(A\). Which means, each element has two possibilities, in \(A\) or not in \(A\). Hence, the cardinality (i.e.~the size) of the power set is \(2^\mathcal{S}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What did we mean by ``order does not matter'' and ``order matters'' during the lecture.
\end{enumerate}

\begin{itemize}
\item
  Order does not matter: I said when you write out the element of a set, the order does not matter. For instance, in the rolling a six-sided dice, which side would be faced on the top example, we can write \(\mathcal{S} = \{1,2,3,4,5,6\}\), or \(\mathcal{S}^\prime=\{6,5,4,3,2,1\}\), and those two sets are essentially equal to each other. To represent a set, the order does not matter, but we tend to write in a way that is intuitive and easy to understand.
\item
  Order does matter: In rolling two dices example, the dots show on each of the dice is an \emph{ordered pair}, denoted by \((x,y)\). Hence, for instance, \((1,2)\) and \((2,1)\) are different. It is problem-dependent so be careful.
\end{itemize}

\hypertarget{lecture-3-january-12-2024}{%
\chapter{Lecture 3, January 12, 2024}\label{lecture-3-january-12-2024}}

\begin{definition}[Odds]
Odds \textbf{in favour} of an event \(A\) occurring is
\[
  O(A) := \frac{P(A)}{1-P(A)}.
\]
Odds again an event \(A\) is
\[
  \frac{1-P(A)}{P(A)}.
\]
\end{definition}

The range of the odds is \([0,\infty)\).

It provide a measure of the likelihood of a particular outcome to happen.

Abbreviation: ````p:q''.

Note: Probability may be defined through the odds as follow.
\begin{align*}
  &O(A) := \frac{P(A)}{1-P(A)} \\
  &\implies O(A) - P(A)O(A) = P(A) \\
  &\implies O(A) = P(A) (1+O(A)) \\
  &\implies P(A) = \frac{O(A)} {1+O(A)}
\end{align*}

Note: In finite, equally likely sample spaces, computing probabilities amounts to \emph{counting the number of elements in a set}. It will often be difficult to do this manually, so we are looking for clever \emph{counting techniques} in the next chapter.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Chapter 3 Counting Techniques}

Addition rule v.s. Multiplication rule

For addition rule

\begin{itemize}
\tightlist
\item
  Keyword for addition rule is ``\textbf{OR}'';
\item
  \(|A|\) is defined to be the size of the set, aka the cardinality of the set.
\item
  If \(A\) and \(B\) are \emph{disjoint} (i.e.~\(A\cap B = \emptyset\)), then \(|A\cup B| = |A| + |B|\).
\item
  \(A\cup A^c = S\) where \(A \cap A^c = \emptyset\). Thus \(|S|=|A|+|A^c|\).
\end{itemize}

For multiplication rule

\begin{itemize}
\tightlist
\item
  for multiplication rule is ``\textbf{AND}''
\item
  An ordered k-tuple is an ordered set of \(k\) values: \((a_1,a_2,\dots,a_k)\). If the outcomes in A can be wrttien as an ordered k-tuple where there are \(n_1\) choices for \(a_1\), \(n_2\) choices for \(a_2,\dots\) and in general \(n_i\) choices for \(a_i\), then
  \[
  |A| = n_1n_2\cdots n_k = \prod_{i=1}^k n_i.
    \]
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{definition}[Factorial]
Given \(n\) distinct objects, there are
\[
n! = n \times (n-1) \times \ldots 2 \times 1,
\]
different ordered arrangements of length \(n\) that can be made. Note that, we define, \(0! = 1\).
\end{definition}

\begin{itemize}
\tightlist
\item
  We pronounce \(n!\) as ``n factorial''.
\item
  The following recursive definition is useful:
  \[ 
  n! = n \cdot (n-1)!
  \]

  \item

  When working with factorials, we can often cancel terms, e.g.,
  \[ \frac{9!}{7!} = \frac{9\cdot 8 \cdot 7\cdot 6 \cdot \dots \cdot 2 \cdot 1}{7\cdot 6 \cdot \dots \cdot 2 \cdot 1}=9\cdot 8 = 72\]
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{definition}[Permutation]
Given \(n\) distinct objects, a \textbf{permutation} of size \(k\) is an \(ordered\) subset of \(k\) of the individuals. The number of permutations of size \(k\) taken from \(n\) objects is denoted \(n^{(k)}\) and
\[
n^{(k)}=n(n-1)\dots (n-k+1) =\frac{n!}{(n-k)!}.
\]
\end{definition}

The tricky part of this definition is the word ``ordered''. An ordering need not be numerical, for example assigning labels like ``President'' and ``Vice-President'' has the effect of ordering the individuals.

\hypertarget{questions-from-the-class-1}{%
\section{Questions from the class}\label{questions-from-the-class-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Can we express the odds as \(a:b\)?
\end{enumerate}

YES. For instance, the example we saw in class (or the clicker question 1), if we roll a fair six sided dice, and let our event \(A:=\{\text{# is } 5 \}\). Then the odds \(O(A)=\frac{1/6}{1/5}=\frac{1}{5}\). We can see that, there is exactly one possibility we have event \(A\), whereas there are 5 possibilities that \(A\) does not happen (i.e.~the number we roll out is \(1,2,3,4,6\)). We \textbf{can} abbreviate it as ``1:5''. For a good example of Odds, \href{https://en.wikipedia.org/wiki/Odds}{WIKI} provides a good one.

\hypertarget{lecture-4-january-15-2024}{%
\chapter{Lecture 4, January 15, 2024}\label{lecture-4-january-15-2024}}

\begin{definition}[Combination]
Given \(n\) distinct objects, a \emph{combination} of size \(k\) is an \emph{unordered} subset of \(k\) of the individuals. The number of combinations of size \(k\) taken from \(n\) objects is denoted \({n \choose k}\) or \({}_n C_k\) and can be computed as
\[
{n \choose k}=\frac{n^{(k)}}{k!}=\frac{n!}{(n-k)!\ k!}.
\]
\end{definition}

\hypertarget{lecture-5-january-17-2024}{%
\chapter{Lecture 5, January 17, 2024}\label{lecture-5-january-17-2024}}

Properties of the Binomial coefficients

There are some useful/important results about permutation and combination.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(n^{(k)} = n (n - 1)^{(k-1)}\) for \(k \geq 1\)
\item
  \({n \choose k} = \frac{n^{(k)}}{k!}\)
\item
  \({n \choose k} = {n \choose n-k}\) for \(k \geq 0\)
\item
  \({n \choose k} = {n-1 \choose k-1} + {n-1 \choose k}\)
\item
  Binomial theorem: \((1 + x)^n = \sum_{k=0}^n {n \choose k} x^k\)
\item
  \({n \choose k}\) is equal to the \(k\)th entry in the \(n\)th row of \textbf{Pascal's triangle}.
\end{enumerate}

Note: Many of these idenetity may be proven using something called \emph{combinatorial proof}. See \href{https://en.wikipedia.org/wiki/Combinatorial_proof}{Wiki} for an (easy) example.

\begin{proof}[4]
\begin{align*}
{n-1 \choose k-1} + {n-1 \choose k} &= \frac{(n-1)!}{(k-1)! (n-k)!} + \frac{(n-1)!}{k! (n-k-1)!}\\
&= \frac{(n-1)!k }{(k-1)! (n-k)!k} + \frac{(n-1)!(n-k)}{k! (n-k-1)!(n-1)} \\
&= \frac{(n-1)!k + (n-1)! (n-k)}{k! (n-k)!} \\
&- \frac{(n-1)!( k + (n-k))}{k! (n-k)!} \\
&= \frac{(n-1)! n}{k! (n-k)!} \\
&= {n \choose k}
\end{align*}
\end{proof}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Aside: Stirling's formula

\(n!\) grows really fast as \(n\) increases, so sometimes we need to approximate its value for computational reasons.

\textbf{Stirling's formula} provides one such method, and it is given by

\[
n! \sim \sqrt{2 \pi n} \left( \frac{n}{e} \right)^n,
\]
where \(\sim\) means their ratio approaches 1 as \(n\) goes to infinity.

We won't need this approximation, but it's useful to know it exists.

Example of use:
Show that \(2^{-2n}\binom{2n}{n} \approx \sqrt{\frac{2}{\pi n}}\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{example-in-class}{%
\section{Example in class}\label{example-in-class}}

\begin{example}[Application of Stirling's Formula/Approximation for factorial]
Show that \(2^{-2n}{2n \choose n} \approx \sqrt{\frac{1}{\pi n}}\)

\begin{align*}
  2^{-2n}{2n \choose n} &= 2^{-2n}\frac{2n!}{n!n!} \\
  &\approx 2^{-2n} \frac{\sqrt{2\pi (2n)} (2n/e)^{2n}}{\sqrt{2\pi n} (n/e)^{n}\sqrt{2\pi n} (n/e)^{n}}\\
  &= 2^{-2n} \frac{\sqrt{4}}{\sqrt{2}\sqrt{2}} \frac{\sqrt{\pi n}}{\sqrt{\pi n}\sqrt{\pi n}} \frac{(2n)^{2n}}{n^n n^n} \frac{e^{-2n}}{e^{-2n}}\\
  &=  2^{-2n} \frac{1}{\sqrt{\pi n}} 2^{2n}\\
  &= \frac{1}{\sqrt{\pi n}} = \sqrt{\frac{1}{\pi n}}
\end{align*}
\end{example}

\hypertarget{lecture-6-january-19-2024}{%
\chapter{Lecture 6, January 19, 2024}\label{lecture-6-january-19-2024}}

\hypertarget{multinomial-coefficient}{%
\subsection{Multinomial Coefficient}\label{multinomial-coefficient}}

\begin{definition}[Multinomial Coefficient]
Consider \(n\) objects which consist of \(k\) types. Suppose that there are \(n_1\) objects which are of type 1, \(n_2\) which are of type 2, and in general \(n_i\) objects of type \(i\). Then there are
\[
\frac{n!}{n_1 ! n_2! \dots n_k !}
\]
distinguishable arrangements of the \(n\) objects. This quantity is known as a \textbf{multinomial coefficient} and denoted by
\[
\binom{n}{n_1,n_2,\dots,n_k}= \frac{n !}{n_1 ! n_2! \dots n_k !}.
\]
\end{definition}

\textbf{Note}: Multinomial coefficient is an extension of the \emph{binomial coefficient}. In binomial coefficient, there are only \textbf{two groups/objects}, and the first type has size \(n_1\) and the size of the second type is consequently \(n-n_1\), where \(n\) is the total number of objects. Hence we have \({n \choose n_1} = \frac{n!}{n_1! (n-n_1)!}\). Try to compare this with the multinomial coefficient.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{the-birthday-problem}{%
\subsection{The Birthday Problem}\label{the-birthday-problem}}

Suppose a room contains \(n\) people. What is the probability at least two people in the room share a birthday?

\textbf{Assumption}: Suppose that each of the \(n\) people is equally likely to have any of the 365 days of the year as their birthday, so that all possible combinations of birthdays are equally likely.

Let \(A\) be the event that at least two people share a birthday. Then
\[ P(A) = 1 - P(A^c),\]
where \(A^c\) is the event that nobody shares birthday with each other.

For \(n\) people to have unique birthdays, we need to arrange them among 365 days w/o replacement. Thus,
\[|A^c| = 365^{(n)}.\]

For the size of the sample space, we see that each person has 365 possibilities for their birthday. Thus,
\[|S| = 365^n.\]

Since we are assuming that all possible combinations of birthdays are equally likely, our desired probability becomes
\[
P(A) = 1 - P(A^c) = 1 - \frac{365^{(n)}}{365^n} = 1 - \frac{n! {365 \choose n}}{365^n}.
\]

For \(n\in\{100, 30, 23\}\) we find
\[P(A_{100})= .9999997,\;\;\; P(A_{30})=.7063 \;\;\;\; P(A_{23})=.5073.\]

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{chapter-4-probbility-rules-and-conditional-probability}{%
\subsection{Chapter 4 Probbility Rules and Conditional Probability}\label{chapter-4-probbility-rules-and-conditional-probability}}

Review the Venn Diagram

\hypertarget{lecture-7-january-22-2024}{%
\chapter{Lecture 7, January 22, 2024}\label{lecture-7-january-22-2024}}

\hypertarget{some-terminology-about-the-set-thoery.}{%
\subsection{Some terminology about the set thoery.}\label{some-terminology-about-the-set-thoery.}}

\hypertarget{fundamental-law-of-set-algebra}{%
\subsubsection{Fundamental law of set algebra}\label{fundamental-law-of-set-algebra}}

Let \(A\) and \(B\) be any arbitrary sets/events.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Commutative
\end{enumerate}

\[
  A\cup B = B\cup A \quad \text{ and } A\cap B = B\cap A.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Associativity
\end{enumerate}

\[
  (A\cup B)\cup C = A \cup (B\cup C), \quad \text{and } (A\cap B)\cap C =  A \cap (B \cap C).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Distributive Law
\end{enumerate}

\[
  A\cup (B\cap C) = (A \cup B) \cap (A \cap  C) , \quad \text{ and } A \cap (B\cup C) =  (A\cap B) \cup (A\cap C)
\]

\hypertarget{demorgans-laws}{%
\subsubsection{DeMorgan's Laws}\label{demorgans-laws}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \((A\cup B)^c = A^c \cap B^c\) (Complement of an union is the intersection of the complements)
\item
  \(A\cap B)^c = A^c \cup B^c\) (Complement of an intersection is the union of the complements)
\end{enumerate}

\hypertarget{inclusion-exclusion-principle}{%
\subsubsection{Inclusion Exclusion Principle}\label{inclusion-exclusion-principle}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(P(A\cup B ) = P(A) + P(B) - P(A\cap B)\)
\item
  \(P(A\cup B \cup C) = P(A) + P(B) + P(C) - P(A\cap B) - P(A \cap C) - P(B \cap C) + P(A\cap B \ cap C)\)
\item
  Note that we can generalized the (2), and obtain the following by \emph{inducation.} For arbitrary events \(A_1,A_2,\cdots,A_n,\quad n\ge 2\),
  \begin{align*}
  P(\bigcup_{i=1}^n A_i)  &  =\sum_{i}P(A_{i}%
  )-\sum_{i<j}P(A_{i}A_{j})+\sum_{i<j<k}P(A_{i}A_{j}A_{k})\\
  &  -\sum_{i<j<k<l}P(A_{i}A_{j}A_{k}A_{l})+\cdots
  \end{align*}
\end{enumerate}

\hypertarget{independence}{%
\subsection{Independence}\label{independence}}

\begin{definition}[independence]
Any two events \(A\) and \(B\) are said to be \textbf{independent} if
\[
  P(A \cap B) = P(A)\times P(B).
\]
\end{definition}

Note: Intuitively, it means that two events do not have any influence of each other. You will see that how this concept plays an important role in statistics, in particular through something called the \emph{covariance}, which is beyond this course so do not worry about this for now.

\hypertarget{independence-v.s.-multually-exclusivedisjoint}{%
\subsection{Independence v.s. Multually Exclusive/Disjoint}\label{independence-v.s.-multually-exclusivedisjoint}}

Recall the definition of mutually exclusive

\begin{definition}[Mutually Exclusive]
Any two events \(A\) and \(B\) are said to be \textbf{mutually exclusive} or \textbf{disjoint} if
\[
  P(A \cap B) = 0.
\]
\end{definition}

Note:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \(A\) and \(B\) are mutually exclusive, \(A\) and \(B\) may NOT be independent!
\item
  \(A\) and \(B\) CAN only be mutually exclusive and independent when either \(A\), \(A\), or both are the empty set \(\emptyset\).
\end{enumerate}

\begin{lemma}
Let two events \(A\) and \(B\) such that NOT both events are trivial events (empty set). If \(A\) and \(B\) are independent and mutually exclusive/disjoint, then either \(P(A) = 0\) or \(P(B) = 0\).
\end{lemma}

\hypertarget{lecture-8-january-24-2024}{%
\chapter{Lecture 8, January 24, 2024}\label{lecture-8-january-24-2024}}

\begin{definition}[Conditional Probability]
The conditional probability of an event \(A\) given an event \(B\), assuming \(P(B)>0\), is

\[
  P(A \mid B) = \frac{P(A\cap B)}{P(B)}.
\]
\end{definition}

\begin{definition}[Equivalent definition of independence]
Two events \(A\) and \(B\) are independent, if
\[
P(A|B)=P(A),
\]
provided \(P(B)>0\).
\end{definition}

\hypertarget{properties-of-conditional-probability}{%
\subsection{Properties of Conditional Probability}\label{properties-of-conditional-probability}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(0 \le P(A \mid B) \le 1\).
\end{enumerate}

This follows from the fact that if \(A \subset B\) then \(P(A) \le P(B)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \(P(A^c \mid B) = 1-P(A \mid B)\).
\item
  If \(A_1\) and \(A_2\) are disjoint (i.e.~\(P(A_1\cap A_2)=\emptyset\): \(P(A_1 \cup A_2 \mid B) = P(A_1 \mid B) + P(A_2 \mid B)\).
\item
  \(P(S \mid B)= 1 = P(B \mid B)\).
\end{enumerate}

\begin{definition}[Product rule]
For any events \(A\) and \(B\), we have
\[
P(A\cap B) = P(A\mid B) P(B)  = P(B \mid A) P(A).
\]
\end{definition}

\hypertarget{lecture-9-january-26-2024}{%
\chapter{Lecture 9, January 26, 2024}\label{lecture-9-january-26-2024}}

\hypertarget{law-of-total-probability}{%
\subsection{Law of Total Probability}\label{law-of-total-probability}}

\begin{definition}[Partition]
A sequence of sets \(B_1,B_2,...,B_k\) are said to \textbf{partition} the sample space \(S\) if \(B_i \cap B_j = \emptyset\) for all \(i \ne j\), and \(\cup_{j=1}^k B_j = S\).
\end{definition}

\begin{theorem}[Law of Total Probability]
Suppose that \(B_1,B_2,...,B_k\) partition \(S\). Then for any event \(A\),
\[
P(A) = P(A | B_1) P(B_1) + P(A | B_2) P(B_2) + \cdots +P(A | B_k) P(B_k).
\]
\end{theorem}

Note: It is a simple usage of LTP such that
\[
  P(A) = P(A\cap B) + P(A \cap B^c),
\]
since \(B\) and \(B^c\) partition \(S\) (i.e.~\(B\cup B^c = S\) and \(B\cap B^c = \emptyset\))

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{bayes-rule}{%
\subsection{Bayes Rule}\label{bayes-rule}}

If we can calculate the conditional profitability, then we may calculate the desire probability by using 1) LTP, 2) definition of conditional probability, and 3) property of the sets (through the Venn diagrams). However, sometimes we have to \emph{FLIP} the event and the conditioning event. This brings us to the \textbf{Bayes Theorem}.

\begin{theorem}[Bayes Theorem]
Suppose that \(B_1,B_2,...,B_k\) partition \(S\). Then for any event \(A\),
\[
P(B_i \mid A ) =  \frac{P(A \mid B_i)P(B_i)}{\sum_{j=1}^k P(A \mid B_j) P(B_j) }.
\]
\end{theorem}

This concludes Chapter 4!.

\hypertarget{lecture-10-january-29-2024}{%
\chapter{Lecture 10, January 29, 2024}\label{lecture-10-january-29-2024}}

We begin \textbf{Chapter 5} in this lecture!

\hypertarget{chapter-5.-discrete-random-variable}{%
\subsection{Chapter 5. Discrete Random Variable}\label{chapter-5.-discrete-random-variable}}

\begin{definition}[Random Variable]
A \emph{random variable} is a function that maps assigns a real number \(\mathbb{R}\) to each point in a sample space \(S\). That is, \(X\) is a random variable if
\[X:S\to \mathbb{R}\].
\end{definition}

\begin{definition}[Range]
The values that a random variables takes is called the \emph{range} of the random variable. We often denote the range of a random variable \(X\) by \(X(S)\).
\end{definition}

\begin{definition}[Discrete random variable]
The \emph{discrete} random variables take integer values, or more generally, values in a countable set (i.e.~finite or countably infinite set). That is, its range is a discrete/countable subset of \(\mathbb{R}\).
\end{definition}

\begin{definition}[Continuous random variable]
A random variable is \emph{continuous} if its range is an interval that is a subset of \({\mathbb R}\) (e.g.~\${[}0,1{]}, (0,\infty), \{\mathbb R\} \$).
\end{definition}

\begin{definition}[Probability (mass) function]
The \emph{probability (mass) function} of a \emph{discrete} random variable \(X\) is the function
\[
f_X(x) = P(X=x),\quad \text{ for } x\in \mathbb{R},
\]
which is non-zero at at most countably many values.
\end{definition}

Notation: We write \(P(X=x)\) as the shorthanded notation for \(P(\{\omega \in S : X(\omega)=x\})\).

Notation: We can write \(f_X(x)=P(X^{-1}(x))=(P\circ X^{-1})(x)\). We call this as \emph{push-forward probability measure}.

Note: The definition \(f_X\) is valid for all \(x\), but the value is zero when \(x\) is outside the range of the random variable \(X\). (This is called the null set).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Properties of probability mass function \(f\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(f_X(x)\in[0,1]\) for all \(x\), and
\item
  \(\sum_{x\in X(\omega)}f_X(x) =1\). i.e.~sum of the probability on ALL the events equal to \(1\).
\end{enumerate}

\hypertarget{lecture-11-january-31-2024}{%
\chapter{Lecture 11, January 31, 2024}\label{lecture-11-january-31-2024}}

\hypertarget{distinction-of-the-definition-discrete-of-the-sample-space-and-the-random-variable}{%
\section{Distinction of the definition ``discrete'' of the sample space and the random variable}\label{distinction-of-the-definition-discrete-of-the-sample-space-and-the-random-variable}}

Recall the definition of the \emph{Range of a random variable} from last lecture:
::: \{.definition name=``Range''\}
The values that a random variables takes is called the \emph{range} of the random variable. We often denote the range of a random variable \(X\) by \(X(S)\).
:::

\begin{itemize}
\item
  We say that, a \textbf{random variable} is discrete if its range \(X(\omega)\) is discrete (finite or countable, in another word, we can say it is \emph{at most countable}).
\item
  We say, a sample space \(S\) is discrete if \(S\) is finite or countable.
\end{itemize}

The sample space \(S\) and the range of the random variable are two different things, so do not get confused! We can have a discrete random variable while the sample space \(S\) is continuous!

\hypertarget{cumulative-distribution-function}{%
\section{Cumulative distribution function}\label{cumulative-distribution-function}}

\begin{definition}[Range]
The \textbf{cumulative distribution function} (cdf) of a random variable \(X\) is
\[
F_X(x) = P(X \le x),\;\; x \in {\mathbb{R}}.
\]
\end{definition}

Note: The cumulative distribution function \(F_X\) is \textbf{always defined} over the entire real line \(\mathbb{R}\), while the probability function may not always be defined! Hence, the cumulative distribution function is an useful tool! (but do not worry about it now.)

Notation: \(F_X(x) = P(X\le x) = P(\{\omega \in S : X(\omega)\in x\}).\)

If \(X\) is \emph{discrete with probability function \(f_X\) (i.e.~if \(f_X\) exists)}, then we can calculate the cdf from summing up the pdf as
\[
F_X(x)=P( X \le x ) = \sum_{y:\; y\le x}f_X(y).
\]

\hypertarget{properties-of-the-cumulative-distribution-function}{%
\subsection{Properties of the cumulative distribution function}\label{properties-of-the-cumulative-distribution-function}}

Let \(F_X(\cdot)\) be a cdf. Then the following holds

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(F_X(x)\in [0,1]\)
\item
  \(F_X(x) \le F_x(y)\) whenever \(x<y\) (i.e.~\(F_X(\cdot)\) is a non-increasing function.)
\item
  \(\lim\limits_{x \to - \infty } F_X(x)=0\), and \(\lim\limits_{x \to \infty } F_X(x) = 1\).
\item
  \(F_X\) is \emph{right continuous}, i.e., \(F(x_0)=\lim_{x\downarrow x_0} F(x)\) for all \(x_0\in\mathbb{R}\).
\end{enumerate}

\hypertarget{special-distributions-with-names}{%
\section{Special distributions with names}\label{special-distributions-with-names}}

\hypertarget{discrete-uniform-distribution}{%
\subsection{Discrete uniform distribution}\label{discrete-uniform-distribution}}

The first named distribution we look at is the \emph{discrete uniform distribution}

\begin{definition}[Discrete uniform distribution]
uppose the range of the random variable \(X\) is \(\{a,a+1,\dots, b\}\), where \(a,b\in\mathbb{Z}\), and suppose all values are equally likely. Then we say that \(X\) has a \textbf{discrete uniform distribution} on \(\{a,a+1,\dots,b\}\), shorthand: \(X \sim U[a,b]\).
\end{definition}

\hypertarget{probability-function-and-distribution-function}{%
\subsubsection{Probability function and distribution function}\label{probability-function-and-distribution-function}}

If \(X \sim U[a,b]\), then its probability function is given by
\[
   f_X(x)= P(X = x) = \begin{cases} \frac{1}{b - a + 1}, &\quad\text{ if }x \in\{a,a+1,\dots,b\}, \\ 0, &\quad\text{ otherwise} \end{cases}   \]
and corresponding (cumulative) distribution function is
\[
   F_X(x)= P(X \leq x) = \begin{cases} 0, &\quad\text{ if } x<a\\
   \frac{\lfloor x\rfloor - a + 1}{b - a + 1}, &\quad\text{ if }x \in\{a,a+1,\dots,b\}, \\ 
   1, &\quad\text{ if } x\geq b,\end{cases}   \]
where \(\lfloor x\rfloor=\max\{z\in\mathbb{Z}: z\leq x\}\) is the \emph{floor function}.

\hypertarget{lecture-12-feburary-02-2024}{%
\chapter{Lecture 12, Feburary 02, 2024}\label{lecture-12-feburary-02-2024}}

\hypertarget{hypergeometric-distribution}{%
\section{Hypergeometric distribution}\label{hypergeometric-distribution}}

\begin{definition}[Hypergeometric distribution]
Consider a population that consists of \(N\) objects, of which \(r\) are considered \emph{successes} and the remaining \(N-r\) are considered \emph{failures}. Suppose that a subset of size \(n\) (with \(n\leq N\)) is drawn from the population WITHOUT REPLACEMENT. Let \(X\)=Number of successes obtained, then we say \(X\) follows a \textbf{hypergeometric distribution} with parameters \((N,r,n)\). We sometimes write \(X \sim hyp(N,r,n)\) or \(X\sim HG(N,r,n)\).
\end{definition}

\hypertarget{range-of-the-hypergeomnetric-distribution}{%
\subsection{Range of the Hypergeomnetric distribution}\label{range-of-the-hypergeomnetric-distribution}}

\begin{itemize}
\tightlist
\item
  We cannot have more successes than there are (\(r\)) \(\Rightarrow\) \(x\leq r\)
\item
  We cannot have more successes than trials (\(n\)) \(\Rightarrow\) \(x\leq n\)
\item
  When there are more trials than failures (\(n>(N-r)\)) we will for sure have at least \(n-(N-r)\) successes \(\Rightarrow\) \(x\geq \max\{0, n-(N-r)\}\).
\item
  Overall, we have \textbf{\(\max\{0, n-(N-r)\} \leq x \leq \min\{r,n\}\)}.
\end{itemize}

\hypertarget{probability-function-of-hypergeometric-distribution}{%
\subsection{Probability function of hypergeometric distribution}\label{probability-function-of-hypergeometric-distribution}}

\begin{itemize}
\tightlist
\item
  Total number of of subsets of size \(n\): \(\binom{N}{n}\).
\item
  Number of ways to select \(x\) successes out of \(r\) successes: \(\binom{r}{x}\).
\item
  Number of ways to choose remaining \(n-x\) failures from \(N-r\) failures: \(\binom{N-r}{n-x}\).
\item
  Thus,
  \[f(x) = \frac{\binom{r}{x}\binom{N-r}{n-x}}{\binom{N}{n}},\]
  where \(\max\{0, n-(N-r)\} \leq x \leq \min\{r,n\}\) and 0 otherwise.
\end{itemize}

\hypertarget{bernoulli-and-binimial-distributions}{%
\section{Bernoulli and Binimial distributions}\label{bernoulli-and-binimial-distributions}}

\begin{definition}[Bernoulli trail]
A \textbf{Bernoulli trial} with probability of success \(p\) is an experiment that results in either a success or failure, and the probability of success is \(p\).
\end{definition}

\begin{definition}[Bernoulli distribution]
If a random variable \(X\) represents the number of successes in a Bernoulli trial with probability of success \(p\), it follows the \emph{Bernoulli distribution}, and we denote it as
\[
X \sim Bernoulli(p).
\]
\end{definition}

\hypertarget{probability-function-and-cumulative-distribution-function}{%
\subsection{Probability function and cumulative distribution function}\label{probability-function-and-cumulative-distribution-function}}

\hypertarget{bernoulli}{%
\subsection{Bernoulli}\label{bernoulli}}

If \(X\sim Bern(p)\), the pf of \(X\) is
\[ f_X(0)=1-p,\quad f_X(1)=p,\quad f_X(x)=0\,\,\text{ for }x\not\in\{0,1\}\]
and the cdf is
\[ F_X(x)=\begin{cases} 0, &\text{ if }x<0, \\ 1-p, &\text{ if } 0\leq x < 1,\\ 1, &\text{ if }x\geq 1\end{cases}\]

\hypertarget{binomial}{%
\subsection{Binomial}\label{binomial}}

\begin{definition}[Bernoulli distribution]
If we have \(N\) independent runs and record the numbers of successes obtained in these \(n\) runs, then \(X\) is said to have a binomial distribution, denoted by \(X\sim Bin(n,p)\).
\end{definition}

Note: The probability function of \(X\sim Bin(n, p)\) is
\[ f(x) = \binom{n}{x} p^x(1-p)^{n-x},\quad x=0,1,2,\dots,n\]
and 0 otherwise.

\hypertarget{relationship-and-difference-between-binomial-and-hypergeometric}{%
\section{Relationship and difference between binomial and hypergeometric}\label{relationship-and-difference-between-binomial-and-hypergeometric}}

\begin{itemize}
\tightlist
\item
  Binomial and hypergeometric distributions are fundamentally different!
\item
  In Binomial models, we pick \textbf{WITH} replacement, in the hypergeometric model \textbf{WITHOUT} replacement.
\item
  If \(N\) is large and \(n\) is small, the chance we pick the same object twice is small.
\item
  Thus, letting \(r/N=p\), \(X\sim Hyp(N,r,n)\) and \(Y\sim Bin(n,p)\), then we can \textbf{APPROXIMATE}
  \[ P(X \leq k) \approx P(Y\leq k).\]
  (more precisely, in the limit as \(N\rightarrow\infty\) with \(r/N\rightarrow p\) (the ratio of successes converges to the success probability).
\item
  See pages 86/87 and later in the course for more.
\item
  We'll see an example next time.
\end{itemize}

\hypertarget{lecture-13-feburary-05-2024}{%
\chapter{Lecture 13, Feburary 05, 2024}\label{lecture-13-feburary-05-2024}}

\hypertarget{binomial-v.s.-hypergeometric}{%
\section{Binomial v.s. hypergeometric}\label{binomial-v.s.-hypergeometric}}

\begin{itemize}
\tightlist
\item
  \(Bin(n,\frac{r}{N})\) and \(hyp(N,r,n)\) are fundamentally different!
\item
  If you have an urn with \(r\) successes and \(N-r\) failures\ldots{}

  \begin{itemize}
  \tightlist
  \item
    \ldots{} and you draw \(n\) items, then the number of successes is\ldots{}

    \begin{itemize}
    \tightlist
    \item
      \ldots{} Binomial: drawn \blue{with} replacement, \ldots{}
    \item
      \ldots{} Hypergeometric: drawn \blue{without} replacement.
    \end{itemize}
  \end{itemize}
\item
  \(N\gg n \Rightarrow\) chance we pick same object twice w/ replacement small.
\item
  \alert{Approximation:} For \(p=\frac{r}{N}\), \(X\sim Hyp(N,r,n)\) and \(Y\sim Bin(n,p)\)
  \[ P(X \leq k) \approx P(Y\leq k).\]
  (more precisely, in the limit as \(N\rightarrow\infty\) with \(r/N\rightarrow p\)).
\end{itemize}

\hypertarget{negative-binomial-distribution}{%
\section{Negative binomial distribution}\label{negative-binomial-distribution}}

\begin{definition}[Negative Binomial]
Consider an experiment with two possible outcomes \emph{success} (Su) or \emph{failure} (F). Without loss of generality, assume that the \(P(Su)=p\) (so \(P(F)=1-P(Su)= 1-p\)). Repeat the experiment \textbf{independently} until a specified number of \(k\) successes have been observed. Denote \(X\) the number of failures before the \(k\)-th suceess, then \(X\sim NegBin(k,p)\).
\end{definition}

\hypertarget{probability-function}{%
\subsection{Probability function}\label{probability-function}}

The probability function of \(X\sim NegBin(k,p)\) is
\[ f(x)=P(X=x)=\binom{x+k-1}{x}p^k(1-p)^x,\quad x=0,1,2,\dots\]
since there are \(\binom{x+k-1}{x}\) to choose \(x\) positions among the first \(x+k-1\) positions to be a failure (and the remaining ones are automatically success), and each of these sequence of outcomes has probability \(p^k(1-p)^x\).

\hypertarget{binomial-v.s.-negative-binomial}{%
\section{Binomial v.s. Negative Binomial}\label{binomial-v.s.-negative-binomial}}

\begin{itemize}
\item
  Binomial distribution: We know number of trials \(n\), but we do not know how many successes.
\item
  Negative Binomial distribution: We know the number of successes \(k\), but we do not know how many trials will be needed.
\end{itemize}

\hypertarget{geometric-distribution}{%
\section{Geometric distribution}\label{geometric-distribution}}

\begin{definition}[Geometric]
Consider an experiment with two possible outcomes \emph{success} (Su) or \emph{failure} (F). Without loss of generality, assume that the \(P(Su)=p\) (so \(P(F)=1-P(Su)= 1-p\)). Repeat the experiment \textbf{independently} \textbf{before the 1st success} has been observed. Denote \(X\) the number of failures before 1st success, then \(X\sim Geo(p)\).
\end{definition}

Note: The Geometric distribution is a special case of the negative binomial distribution: \(Geo(P) \sim Neg(k=1,p)\).

\hypertarget{probability-function-and-distribution-function-1}{%
\subsection{Probability function and distribution function}\label{probability-function-and-distribution-function-1}}

\begin{itemize}
\tightlist
\item
  If \(X\sim Geo(p)\), then \(X\) has probability function
  \[ f(x) = P(X=x)= (1-p)^x p,\quad x\in\{0,1,2,\dots\}.\]
\end{itemize}

\[ F(x)=P(X\leq x) 
= P(X\leq \floor{x}) = 
\sum_{k=0}^{\floor{x}} (1-p)^k p =
1-(1-p)^{\floor{x}+1}\]
if \(x\geq 0\) and \(0\) otherwise.

\begin{itemize}
\tightlist
\item
  Note that \(P(X>x)=1-F(x)=(1-p)^{\floor{x}+1}\) which is nice for computations!
\end{itemize}

\hypertarget{memoryless-property}{%
\subsection{Memoryless property}\label{memoryless-property}}

Let \(X \sim Geo(p)\) and \(s,t\) be non-negative integers. Then, the following equation holds.
\[
P(X \geq s+t | X \geq s) = P(X \geq t).
\]

\hypertarget{aside-reason-to-call-the-negative-binomial-distribution}{%
\subsection{Aside, Reason to call the Negative binomial distribution}\label{aside-reason-to-call-the-negative-binomial-distribution}}

(This is contributed by Jeffery!)

Can extend binomial coefficients to \textbf{negative or fractional} ``top'\,' part.

\[\binom{\theta}{x} := \frac{\theta^{(X)}}{x!} = \frac{\theta(\theta-1)(\theta-1)...(\theta-x+1)}{X!}\]

Note: ``bottom'\,' part of coefficient still a non-negative integer.

Then
\begin{align*}
    \binom{-k}{x} 
        & = \frac{-k(-k-1)...(-k-x+1)}{x!} \\
        & = (-1)^x \frac{(x+k-1)(x+k-2)...((x+k-1)-x+1)}{x!}\\
        & = (-1)^x \binom{x+k-1}{x}
\end{align*}
So
\[
    f_X(x) = \binom{x+k-1}{x}p^k(1-p)^x = (-1)^x \binom{-k}{x} p^k(1-p)^x 
\]

\hypertarget{lecture-14-feburary-07-2024}{%
\chapter{Lecture 14, Feburary 07, 2024}\label{lecture-14-feburary-07-2024}}

\hypertarget{poisson-distribution}{%
\section{Poisson distribution}\label{poisson-distribution}}

\begin{definition}[Poisson distribution]
We say the random variable \(X\) has a \{\bf Poisson\} distribution with parameter \(\mu > 0\) if
\[
f(x) = e^{-\mu} \frac{ \mu^x}{x!},\;\;x=0,1,2,\dots\]
\end{definition}

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

We write \(X\sim Poisson(\mu)\) or \(Poi(\mu)\), where \(\mu\) is called the \emph{rate} parameter.

\hypertarget{interpreation-of-the-poisson-distribution}{%
\subsection{Interpreation of the Poisson distribution}\label{interpreation-of-the-poisson-distribution}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Limiting case of binomial distribution}, where you fix \(\lambda = np\) , and let \(n \rightarrow \infty\) and \(p \rightarrow 0\) (This can be a consequence of b))
\item
  \emph{Poisson Process}
\end{enumerate}

\hypertarget{poisson-as-the-limiting-distribution-of-the-binomial-distribution}{%
\section{Poisson as the limiting distribution of the binomial distribution}\label{poisson-as-the-limiting-distribution-of-the-binomial-distribution}}

One way to view the Poisson distribution is to consider the limiting case of binomial distribution, where you fix \(\mu = np\) , and let \(n \rightarrow \infty\) and \(p \rightarrow 0\).

One can show that if \(n\to \infty\) and \(p=p_n \to 0\) as \(n\to \infty\) in such a way that \(n p_n \to \mu\), then
\[
{n \choose x} p^x (1-p)^{n-x} \to e^{-\mu} \frac{ \mu^x}{x!},\;\;\;as\;\;\; n\to \infty.
\]
Actually here, it is something called the *convergence in distribution**.

\hypertarget{poisson-process}{%
\section{Poisson process}\label{poisson-process}}

Consider counting the number of occurrences of an event that happens at random points in time (or space). Poisson process is the \emph{counting process} that satisfies the following

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Independence}: the number of occurrences in non-overlapping
  intervals are independent.
\item
  \textbf{Individuality}: for sufficiently short time periods of length
  \(\Delta t,\) the probability of 2 or more events occurring in the interval is
  close to zero
  \[
  \frac{P\left(  \text{2 or more events in }(t,t+\Delta_t)\right)}{\Delta_t}  \rightarrow 0,\;\; \Delta_t \to 0
  \]
\item
  \textbf{Homogeneity or Uniformity}: events occur at a uniform or
  homogeneous rate \(\lambda\) and proportional to time interval \(\Delta_t\), i.e.
  \[
  \frac{P\left(  \text{one event in }(t,t+\Delta_t)\right) - \lambda\Delta_t }{\Delta_t}  \to 0.
  \]
\end{enumerate}

If \(X=\) occurrences in a time period of length \(t\), then
\[X\sim Poi(\lambda t).\]

\begin{definition}[Poisson process]
A process that satisfies the prior conditions on the occurrence of events is often called a \textbf{Poisson process}. More precisely, if \(X_t, \; \text{for } t\ge0,\) (a random variable for each \(t\)) denotes the number of events that have occurred up to time \(t\), then \(X_t\) is called a Poisson process.
\end{definition}

\hypertarget{side-notes-rigorous-definition-of-convergence-in-distribution}{%
\section{Side notes -- Rigorous definition of convergence in distribution}\label{side-notes-rigorous-definition-of-convergence-in-distribution}}

This section is just served as a reference for those of you who are interested in the rigorous definition of \emph{convergence in distribution}. Do not worry too much if you are not interested in knowing those.

\begin{definition}[Convergence in distribution]
Let \((F_n)_{n\in\mathbb{N}}\) and \(G\) be CDFs. Let \(c(G) = \{x\in\mathbb{R} : G \text{ is cts. at }x\}\) be the set of continuity points of \(G\). \(F_n\) \emph{converges in distribution} to \(G\) if
\begin{align}
    \forall x\in c(G) \quad F_n(x)\to G(x)  \label{eq:convdist}
\end{align}
If \(X_n\) has CDF \(F_n\) for each \(n\) and \(Y\) has CDF \(G\) and \eqref{eq:convdist} holds then \(X_n\) converges in distribution to \(Y\). Denoted \(X_n \stackrel{d}{\to} Y\), or \(F_n \stackrel{d}{\to} G\)
\end{definition}

\hypertarget{lecture-15-feburary-09-2024}{%
\chapter{Lecture 15, Feburary 09, 2024}\label{lecture-15-feburary-09-2024}}

\hypertarget{review-of-the-distributions-we-covered-before}{%
\section{Review of the distributions we covered before}\label{review-of-the-distributions-we-covered-before}}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0739}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4877}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4384}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(f(x)=P(X=x)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(U[a,b]\) & \(\frac{1}{b-a+1},\, x=a,a+1,\dots,b\) & Sample from \(\{a,a+1,\dots,b\}\) once uniformly at random\textbackslash{} \\
\(Bin (n,p)\) & \(\binom{n}{x}p^x(1-p)^{n-x},\,x=0,1,\dots,n\) & \(\#\) of successes in \(n\) indep. trials with success prob. \(p\). \\
\(Hyp(N,r,n)\) & \(\frac{\binom{r}{x}\binom{N-r}{n-x}}{\binom{N}{n}},\) \(\max\{0, n-(N-r)\} \leq x \leq \min\{r,n\}\) & \(\#\) of successes in \(n\) draws without replacement from \(N\) objects with \(r\) successes. \\
\(NegBin(k,p)\) & \(\binom{x+k-1}{x}p^k(1-p)^x,\, x=0,1,\dots,\) & \(\#\) of failures until \(k\) successes in indep. trials with success prob. \(p\) \\
\(Geo(p)\) & \(p(1-p)^x,~ x=0,1,\dots \) & \(\#\) of failures until first success in indep. trials with success prob. \(p\) \\
\(Poi(\mu)\) & \(\exp(-\mu) \mu^x/x!,~ x=0,1,\dots \) & \(\#\) of occurrences in Poi process. \\
\end{longtable}

\hypertarget{lecture-16-feburary-12-2024}{%
\chapter{Lecture 16, Feburary 12, 2024}\label{lecture-16-feburary-12-2024}}

\hypertarget{chapter-7-expectation-and-variance}{%
\section{Chapter 7 Expectation and Variance}\label{chapter-7-expectation-and-variance}}

Probability and statistics are closely related to data; we often try to ``extract'' additional information from data.

Some simple way to analyse and visualize data are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  frequency table
\item
  frequency histogram
\end{enumerate}

However, sometimes it is unclear how to define the groups in the frequency or in the histogram. Hence, we often would like to have more concise defined ways to analyse the random variable and its associated distribution. We call those numerical values as the (summary) \emph{statistics}.

\begin{definition}[Sample mean]
Let \(x_1, \ x_2, \ldots, \ x_n\) be \(n\) realizations of a random variable \(X\) (such a set is called a \textbf{sample}). The \emph{sample mean} is defined as
\[
\bar{x} = \frac{1}{n}  \sum_{i=1}^n x_i
\]
\end{definition}

Note: there are other summary

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample median: a value such that half of the results are below it and the other half above it, when the sample is arranged in numerical order.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Median is more \emph{robust} against some abnormally big/small observations, or recording errors.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Sample mode: The most frequently-occuring value in a sample.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  We may have more than one mode.
\end{itemize}

\hypertarget{theoretical-mean-and-the-sample-mean}{%
\section{Theoretical mean and the sample mean}\label{theoretical-mean-and-the-sample-mean}}

We can compute \emph{statistics} for a random variable \(X\) directly if we know its distribution. Such a mean would be \emph{theoretical}, as we are working from its probability distribution rather than an actual sample.

That means, we can do experiment to get sample, then compute the sample mean, while if we know the distribution, we can compute the theoretical mean without any samples.

\hypertarget{definition}{%
\subsection{Definition}\label{definition}}

\begin{definition}[(Theoretical) Mean/Expectation/First moment]
Suppose \(X\) is a discrete random variable with probability function \(f_X(x)\). The expected value of \(X\), denoted by \(E[X]\), is then the number
\[
E[X] = \sum_{x\in X(S) } x \ f_X(x) = \sum_{x\in X(S) } x \ P(X=x),
\]
provided the sum converges absolutely (i.e., if \(\sum_{x\in X(S) } |x| \ f_X(x)<\infty\))
\end{definition}

\hypertarget{interpretation}{%
\subsection{Interpretation}\label{interpretation}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Geometrical interpretation: \(E[X]\) is the \emph{balancing point} of the probability function \(f(x)\).
\item
  \(E[X]\) is what the average of many, many independent realizations of the random variable \(X\) would approach (\textbf{Law of large numbers}).
\end{enumerate}

\hypertarget{lecture-17-feburary-14-2024}{%
\chapter{Lecture 17, Feburary 14, 2024}\label{lecture-17-feburary-14-2024}}

\hypertarget{more-about-expectation}{%
\section{More about expectation}\label{more-about-expectation}}

Some observations we made from the example we went through in class.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Suppose \(X\) is a random variable satisfying \(a \le X(\omega) \le b\) for all \(\omega \in S\). Then \(a<E[X]<b\).
\item
  We may think that the expectation is a \textbf{weighting} of the values \(x\in X(S)\) by its probability function (which is always positive, and sum up to one).
\end{enumerate}

\hypertarget{law-of-unconscious-statistician}{%
\section{Law of Unconscious Statistician}\label{law-of-unconscious-statistician}}

If
\[
g: {\mathbb R} \to {\mathbb R},
\]
and \(X\) is a random variable with probability function \(f\), then \(g(X)\) is a random variable taking values \(g(X(S))\) and

\[
E[g(X)] = \sum_{x \in X(S)} g(x) f(x)
\]

NOTE: In general, \(E[g(X)]\ne g(E[X])\)!

e.g.~For an arbitrary \emph{convex} function \(g(X)\), \(g\{E(X)\} \le E\{g(x)\}\). This is a famous theorem called \textbf{Jansen's inequality}.

\hypertarget{tricks}{%
\section{Tricks}\label{tricks}}

Sometimes, in order to calculate the expectation, some terminologies may help

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For \(x\in X(S)\), \(\sum_{x\in X(S)} f_X(x)=1\).
\end{enumerate}

\hypertarget{property-of-expectation---linearity}{%
\section{Property of expectation - linearity}\label{property-of-expectation---linearity}}

Suppose the random variable \(X\) has \(E[X]=\mu\). Then for any constants \(a,b\in\mathbb{R}\),
\[ E[aX+b]= a \mu + b = a E[X]+b\]

If we have 2 random variables \(X\) and \(Y\), and three constants, \(a,b,c\in \mathbb{R}\), then
\[
  E[aX+bY + c] = aE[X] + bE[Y] +c.
\]

\hypertarget{proof.}{%
\subsection{Proof.}\label{proof.}}

\begin{proof}
By the \emph{Law of unconscious statistician} with \(g(x)=ax+b\), we find
\begin{align*}
E[aX+b] &=\sum_{x\in X(S)} (ax+b) f(x)\\
& = a \cdot  \sum_{x\in X(S)} x f(x) + b  \cdot \sum_{x\in X(S)} f(x) \\
&= a\cdot  E[X]  + b \cdot 1
\end{align*}
\end{proof}

\hypertarget{mean-of-binomial-distribution}{%
\section{Mean of binomial distribution}\label{mean-of-binomial-distribution}}

If \(X \sim Binomial(n,p)\), then \(E[X] = np\)

\begin{proof}
Suppose \(X \sim Bin(n,p)\). Then we have
\begin{align*}
E[X] &= \sum_{x=0}^n x\cdot \binom{n}{x}  p^x (1-p)^{n-x}\\
&= \sum_{x=1}^n x\cdot \frac{n!}{(n-x)!x!} \cdot p^x (1-p)^{n-x}\\
&= \sum_{x=1}^n \frac{x}{x(x-1)!} \frac{n(n-1)!}{(n-x)!} p p^{x-1} (1-p)^{n-x}\\
&= \sum_{x=1}^n \frac{1}{(x-1)!}\frac{n(n-1)!}{(n-x-1+1)!} p p^{x-1} (1-p)^{n-x-1+1}\\
&= np \sum_{x=1}^n \frac{1}{(x-1)!}\frac{(n-1)!}{((n-1)-(x-1))! (x-1)!} p\cdot p^{x-1} (1-p)^{(n-1)-(x-1)}\\
&= np \; \underbrace{\sum_{y=0}^{n-1} \frac{(n-1)!}{((n-1)-y)! y!} \cdot p^{y} (1-p)^{(n-1)-y}}_{=1\text{b/c sum of PF of bin(n-1,p). is 1}}\\
&= np
\end{align*}
\end{proof}

\hypertarget{lecture-18-feburary-16-2024}{%
\chapter{Lecture 18, Feburary 16, 2024}\label{lecture-18-feburary-16-2024}}

\hypertarget{mean-of-poisson-distribution}{%
\section{Mean of Poisson distribution}\label{mean-of-poisson-distribution}}

Let \(Z\sim Poi(\mu)\). Then the expectation of \(Z\) is \(E[Z] = \mu\).

\begin{proof}
Suppose \(X \sim Poi(\mu)\). Then we have
\textbackslash begin\{align*\}
E{[}X{]} \&= \sum\limits\emph{\text{all $x$} x\cdot f(x) \&\& \text{definition}\textbackslash{}
\&= \sum}\{x=0\}\^{}\infty x \cdot e\^{}\{-\mu\} \frac{\mu^x}{x!} \&\& \text{P.F.}\textbackslash{}
\&= \sum\emph{\{x=1\}\^{}\infty x \cdot e\^{}\{-\mu\} \frac{\mu^x}{x!}\textbackslash{}
\&= \mu \sum}\{x=1\}\textsuperscript{\infty e}\{-\mu\} \frac{\mu^{x-1}}{(x-1)!}\textbackslash{}
\&= \mu \underbrace{\sum_{y=0}^\infty e^{-\mu} \frac{\mu^{y}}{y!}}\_\{=1\text{ as sum of p.f.}\}\textbackslash{}
\end{proof}

  \bibliography{book.bib,packages.bib}

\end{document}
